{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision==0.23.0\n",
    "%pip install \"ultralytics<=8.3.40\"\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import supervision as sv\n",
    "import base64\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from enum import Enum\n",
    "# Constants\n",
    "HOME = os.getcwd()\n",
    "!mkdir -p {HOME}/weights\n",
    "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights\n",
    "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "IS_COLAB = True\n",
    "IMAGE_NAME = \"test-1.jpg\"\n",
    "IMAGE_PATH = f\"{HOME}/rising-tea-images/rest-1.jpg\"\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
    "FRAME_COUNT = None\n",
    "MAX_FRAME_COUNT = 50\n",
    "\n",
    "class Color(Enum):\n",
    "    # Convert numpy arrays to tuples which can be properly compared\n",
    "    RED = (1.0, 0.0, 0.0)\n",
    "    GREEN = (0.0, 1.0, 0.0)\n",
    "    YELLOW = (1.0, 1.0, 0.0)\n",
    "    BLUE = (0.0, 0.0, 1.0)\n",
    "    \n",
    "    def to_array(self):\n",
    "        return np.array(self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = SamAutomaticMaskGenerator(sam,\n",
    "        # points_per_side= 16,\n",
    "        # points_per_batch = 64,\n",
    "        # pred_iou_thresh=0.55,\n",
    "        # stability_score_thresh=0.75,\n",
    "        # stability_score_offset=1.0,\n",
    "        # box_nms_thresh = 0.7,\n",
    "        # crop_n_layers = 0,\n",
    "        # crop_nms_thresh = 0.7,\n",
    "        # crop_overlap_ratio = 512 / 1500,\n",
    "        # crop_n_points_downscale_factor= 1,\n",
    "        # point_grids = None,\n",
    "        # min_mask_region_area = 0\n",
    "                                           )\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_dir):\n",
    "    \"\"\"Extract frames from video at 1-second intervals and save them to output directory\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "    save_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Save frame if it corresponds to a second mark (based on FPS)\n",
    "        if frame_count % int(fps) == 0 and save_count < MAX_FRAME_COUNT:\n",
    "            frame_path = os.path.join(output_dir, f\"frame-{save_count:04d}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            save_count += 1\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    global FRAME_COUNT\n",
    "    FRAME_COUNT = save_count\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function that loads an image before adding it to the widget\n",
    "import base64\n",
    "def encode_image(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    encoded = str(base64.b64encode(image_bytes), 'utf-8')\n",
    "    return \"data:image/jpg;base64,\"+encoded\n",
    "if IS_COLAB:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "# extract frames from video (named \"rising-tea-video.mp4\") into \"frames\" folder with names <frame-number>.jpg\n",
    "# add first frame to widget\n",
    "extract_frames(\"rising-tea-video.mp4\", \"frames\")\n",
    "widget = BBoxWidget()\n",
    "first_frame_path = os.path.join(\"frames\", \"frame-0000.jpg\")\n",
    "widget.image = encode_image(first_frame_path)\n",
    "widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Functions\n",
    "def show_mask(mask, ax, input_color):\n",
    "    if input_color is None:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.concatenate([input_color, np.array([0.6])], axis=0)\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0],\n",
    "        pos_points[:, 1],\n",
    "        color=\"green\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0],\n",
    "        neg_points[:, 1],\n",
    "        color=\"red\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(\n",
    "        plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each frame - initialize SAM predictor\n",
    "predictor = SamPredictor(sam)\n",
    "input_points = np.zeros((0, 2))\n",
    "# get user points from widget because it's a list of dicts with x, y, width, height\n",
    "user_points = widget.bboxes\n",
    "for point in user_points:\n",
    "    point_coord = np.array([[point[\"x\"], point[\"y\"]]])\n",
    "    input_points = np.vstack((input_points, point_coord))\n",
    "rim_point, tea_point = sorted(input_points, key=lambda p: p[1], reverse=True)\n",
    "\n",
    "# process each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_masks_using_points(frame, points, labels):\n",
    "    predictor.set_image(frame)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=np.array(points), \n",
    "        point_labels=np.array(labels),\n",
    "        multimask_output=False\n",
    "    )\n",
    "    return masks, scores, logits\n",
    "\n",
    "def predict_masks_using_logits(frame, points, labels, logits, scores, multimask_output=False):\n",
    "    mask_input = logits[np.argmax(scores), :, :]  \n",
    "    predictor.set_image(frame)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=np.array(points), \n",
    "        point_labels=np.array(labels),\n",
    "        mask_input=mask_input[None, :, :],\n",
    "        multimask_output=multimask_output\n",
    "    )\n",
    "        # When multimask_output is True, get the mask with highest score\n",
    "    if multimask_output:\n",
    "        print(\"maximum score\", np.max(scores))\n",
    "        for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "            print(f\"Mask {i+1}, Score: {score}\")\n",
    "        best_mask_idx = np.argmax(scores)\n",
    "        print(\"best mask idx\", best_mask_idx+1)\n",
    "        return masks[best_mask_idx:best_mask_idx+1], scores[best_mask_idx:best_mask_idx+1], logits[best_mask_idx:best_mask_idx+1]\n",
    "    else:\n",
    "        return masks, scores, logits\n",
    "\n",
    "def find_highest_point(mask):\n",
    "    y_coords, x_coords = np.where(mask)\n",
    "    if len(y_coords) == 0:\n",
    "        return 0\n",
    "    max_y_idx = np.argmin(y_coords)\n",
    "    return y_coords[max_y_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_number in range(FRAME_COUNT):\n",
    "    frame_path = os.path.join(\"frames\", f\"frame-{frame_number:04d}.jpg\")\n",
    "    frame = cv2.imread(frame_path)\n",
    "    \n",
    "    rim_mask = predict_masks(\n",
    "      frame, (rim_point, tea_point), (1,0)\n",
    "    )\n",
    "    tea_mask = predict_masks(\n",
    "      frame, (rim_point, tea_point), (0,1)\n",
    "    )\n",
    "\n",
    "    plt.imshow(frame)    \n",
    "    show_mask(rim_mask, plt.gca(),Color.RED.to_array())\n",
    "    show_mask(tea_mask, plt.gca(),Color.BLUE.to_array())\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rim_highest = find_highest_point(rim_mask)\n",
    "tea_highest = find_highest_point(tea_mask)\n",
    "print(f\"rim_highest: {rim_highest}, tea_highest: {tea_highest}\")\n",
    "print(\"difference: \", rim_highest - tea_highest)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
